#import "../template/template.typ": *

/**********************************************************/

= Background

/**********************************************************/

== SmolVLA

#todo(Sam, done: false)[
  Write about the SmolVLA
]



=== Action Expert

#todo(Ezra, done: false)[
  Write about the Action Expert
]

=== Large Language Model

#todo(Ezra, done: false)[
  Write about the LLM
]

When using a VLA model, users need a method to issue text instructions describing the actions they want the robot to take. As a result, the model needs a common way to process language instructions, which is ideally handled by an LLM. The LLM interprets and understands the natural language instructions, turning them into a representation that can be used for reasoning and action planning. 


=== Vision Transformer Model

#todo(Sam, done: false)[
  Write about the Vision Transformer
]

/**********************************************************/

== Allo

#todo(Stanley, done: true)[
  Write about Allo
]

Allo is an accelerator design language that aims to simplify the process of designing accelerators on FPGAs. Developed by the Zhang Research Group at Cornell University, Allo seeks to decouple the functional aspects and computational semantics of a kernel from the hardware details and optimization code. In normal HLS programs, if a user wants to optimize a kernel, they are required to make intrusive source edits to achieve a performance improvement. Instead, Allo separates the functionality of a kernel from the scheduling, allowing users to apply HLS optimizations without modifying the compute kernel itself. 

/**********************************************************/

== Parallelization Schemes

=== Spatial Architectures

#todo(Ezra, done: false)[
  Write about the Vision Transformer

]

=== Temporal Architectures

#todo(Ezra, done: false)[
  Write about the Vision Transformer
]

