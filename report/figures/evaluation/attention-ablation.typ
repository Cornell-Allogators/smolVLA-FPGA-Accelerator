#import "../../template/template.typ": *


#figure(
  kind: table,
  styled-table(
    columns: 6,
    table.header([Dataflow], [QKV P-Factor], [SDP P-Factor], [Latency (ms)], [BRAM %], [DSP %]),
    [False],
    [1],
    [1],
    [188.33],
    [89.34%],
    [5.10%],
    [False],
    [2],
    [1],
    [126.19],
    [89.68%],
    [8.05%],
    [False],
    [2],
    [2],
    [113.41],
    [89.68%],
    [8.05%],
    [False],
    [4],
    [2],
    [66.59],
    [93.38%],
    [13.98%],
    [False],
    [4],
    [4],
    [60.77],
    [107.66%],
    [18.24%],
    [False],
    [8],
    [4],
    [45.96],
    [102.31%],
    [30.05%],
    [False],
    [8],
    [8],
    [42.89],
    [102.31%],
    [34.31%],
    [False],
    [16],
    [8],
    [35.13],
    [104.32%],
    [57.89%],
    [True],
    [1],
    [1],
    [66.02],
    [98.93%],
    [7.23%],
    [True],
    [2],
    [1],
    [51.12],
    [99.16%],
    [12.37%],
    [True],
    [2],
    [2],
    [40.79],
    [99.16%],
    [12.37%],
    [True],
    [4],
    [2],
    [23.84],
    [99.90%],
    [22.56%],
    [True],
    [4],
    [4],
    [20.04],
    [114.19%],
    [26.82%],
    [True],
    [8],
    [4],
    [18.02],
    [121.73%],
    [47.07%],
    [True],
    [8],
    [8],
    [17.83],
    [121.73%],
    [51.33%],
    [True],
    [16],
    [8],
    [17.81],
    [111.41%],
    [91.93%],
  ),
  caption: [
    *Ablation Study of Attention Kernels.* Performance progression from the
    unoptimized baseline to the fully optimized implementation. Key metrics
    include inference latency (ms) and resource consumption (BRAM, DSP) on
    the U280 FPGA.
    _Latency is determined by multiplying expected \# cycles by estimated clock period. It was evaluated over loading all inputs into BRAM as well as the entire execution of self attention up to the pre MLP Layer Norm_
  ],
) <tab:attention-ablation>


